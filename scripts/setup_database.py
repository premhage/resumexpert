import os
from supabase import create_client, Client
from dotenv import load_dotenv

# 1. Load environment variables from the backend directory
# We assume the script is run from the project root or scripts/ folder
env_path = os.path.join(os.path.dirname(os.path.dirname(os.path.abspath(__file__))), 'backend', '.env')
load_dotenv(dotenv_path=env_path)

def verify_connection():
    """Verifies connection to Supabase using credentials from .env"""
    url = os.getenv("SUPABASE_URL")
    key = os.getenv("SUPABASE_KEY")

    if not url or not key:
        print("❌ Error: SUPABASE_URL or SUPABASE_KEY not found in backend/.env")
        return None

    try:
        # Initialize Supabase client
        supabase: Client = create_client(url, key)
        # Make a lightweight call to check connection (e.g., getting basic info)
        # Since we might not have tables, we just check if the client initializes (basic validity)
        # Note: Real connectivity check usually requires a query, but we'll assume auth is okay if no crash so far.
        print(f"✅ Application connected to Supabase project at: {url}")
        return supabase
    except Exception as e:
        print(f"❌ Connection failed: {e}")
        return None

def generate_schema_sql():
    """Defines the SQL schema and saves it to a file."""
    
    schema_sql = """
-- Enable UUID extension for generating unique IDs
CREATE EXTENSION IF NOT EXISTS "uuid-ossp";

-- 1. Resume Analysis Table
-- Stores the core analysis results for a specific uploaded resume and JD
CREATE TABLE IF NOT EXISTS resume_analysis (
    analysis_id UUID PRIMARY KEY DEFAULT uuid_generate_v4(),
    user_id UUID, -- Optional: link to auth.users if authentication is enabled
    resume_filename TEXT NOT NULL,
    job_description_text TEXT,
    overall_score FLOAT,
    keyword_match_score FLOAT,
    semantic_match_score FLOAT,
    section_scores JSONB, -- Example: {"skills": 80, "experience": 60}
    matched_skills JSONB, -- List of skills found
    missing_skills JSONB, -- List of skills missing
    additional_skills JSONB,
    ats_compatibility_score FLOAT,
    resume_text TEXT,
    created_at TIMESTAMP WITH TIME ZONE DEFAULT timezone('utc'::text, now()) NOT NULL
);

-- 2. Role Scores Table
-- Stores scores for different potential roles for the same resume
CREATE TABLE IF NOT EXISTS role_scores (
    role_score_id UUID PRIMARY KEY DEFAULT uuid_generate_v4(),
    analysis_id UUID REFERENCES resume_analysis(analysis_id) ON DELETE CASCADE,
    role_name TEXT NOT NULL,
    role_score FLOAT,
    role_missing_skills JSONB,
    best_fit_role BOOLEAN DEFAULT FALSE
);

-- 3. Recommendations Table
-- Stores specific actionable advice generated by the AI
CREATE TABLE IF NOT EXISTS recommendations (
    recommendation_id UUID PRIMARY KEY DEFAULT uuid_generate_v4(),
    analysis_id UUID REFERENCES resume_analysis(analysis_id) ON DELETE CASCADE,
    recommendation_type TEXT, -- e.g., 'skill', 'project', 'formatting'
    recommendation_text TEXT,
    priority TEXT -- 'critical', 'important', 'nice-to-have'
);

-- 4. Learning Roadmaps Table
-- Stores the generated learning path for the user
CREATE TABLE IF NOT EXISTS learning_roadmaps (
    roadmap_id UUID PRIMARY KEY DEFAULT uuid_generate_v4(),
    analysis_id UUID REFERENCES resume_analysis(analysis_id) ON DELETE CASCADE,
    role_name TEXT,
    roadmap_json JSONB -- Structured roadmap data
);

-- 5. Skill Trends Table (Reference Data)
-- Stores market trend data (updated periodically)
CREATE TABLE IF NOT EXISTS skill_trends (
    skill_name TEXT PRIMARY KEY,
    demand_level TEXT, -- 'high', 'medium', 'low'
    trend_direction TEXT, -- 'rising', 'stable', 'declining'
    average_salary_impact FLOAT,
    job_postings_count INT,
    last_updated TIMESTAMP WITH TIME ZONE DEFAULT timezone('utc'::text, now())
);
    """
    
    output_file = "database_schema.sql"
    with open(output_file, "w", encoding="utf-8") as f:
        f.write(schema_sql)
    
    print(f"\n✅ Schema SQL generated: {output_file}")
    print("⚠️  ACTION REQUIRED: Copy the contents of 'database_schema.sql' and run it in the Supabase SQL Editor to create the tables.")

if __name__ == "__main__":
    print("--- ResumeXpert Database Setup ---")
    conn = verify_connection()
    if conn:
        generate_schema_sql()
